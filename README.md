# Executive Summary

Artificial intelligence (Al) research in complex domains has increasingly relied on computationally intensive methods that require substantial re-sources, creating barriers to participation for researchers with limited computational access. This study addresses this challenge by systematically comparing the performance-resource trade-offs of three prominent Al approaches ―Multi-Agent Reinforcement Learning (MARL), Evolutionary Algorithms (EA), and Monte Carlo Tree Search (MCTS)— in the context of the cooperative board game Pandemic.
The research employs a novel dual evaluation methodology, assessing each approach under both fixed-episode and fixed-resource constraints. A simplified but strategically representative simulation of Pandemic serves as the experimental environment, preserving the core cooperative decision-making challenges while enabling controlled comparison. The study introduces the Cost-Normalized Performance (CNP) metric to quantitatively evaluate algorithmic efficiency by integrating win rate with memory usage and computation time.
Experimental results reveal significant disparities in both performance and resource utilization. MCTS achieved the highest relative win rate among the three approaches with a win rate of 0.87 % under fixed-episode evaluation, despite moderate resource requirements. The relatively low absolute win rates (sub-1 %) stem from evaluating each agent before full convergence had been reached under the strict training-budget protocol, thereby providing a conservative measure of performance. EA demonstrated exceptional resource efficiency with a CNP value approximately 100 times higher than MCTS and 1000 times higher than MARL. Under fixed-resource constraints (24 hours of computation), MCTS completed fewer episodes yet maintained superior performance, highlighting its efficient learning capabilities.
Statistical analysis with 95% confidence intervals confirms the significance of these performance differences. Multi-dimensional evaluation through Pareto analysis and radar charts provides a comprehensive view of the performance-resource landscape, showing that MARL consistently occupies the high-resource/low-performance region, while EA and MCTS offer more favorable efficiency profiles.
These findings challenge the assumption that more computationally intensive approaches necessarily deliver proportionally better results in cooperative decision-making domains. The research demonstrates that meaningful Al performance can be achieved with modest computational resources when appropriate algorithmic approaches are selected. This has important implications for democratizing Al research capabilities and promoting environmentally sustainable development practices.
The methodological framework developed in this study offers a template for future resource-conscious Al evaluations that extend beyond raw performance to consider efficiency, accessibility, and sustainability dimensions.
While implementation quality and domain-specific characteristics limit gen-eralizability, the substantial efficiency advantages observed for EA and MCTS highlight the value of algorithmic selection guided by available computational resources.
